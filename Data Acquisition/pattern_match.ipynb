{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern matching on competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_paths = {\n",
    "    'kaggle': '/Users/hadleydixon/Desktop/gamification_data_analysis/Data/raw_scraping/kaggle_data_first_page_2.json',\n",
    "    'aicrowd': '/Users/hadleydixon/Desktop/gamification_data_analysis/Data/raw_scraping/aicrowd_raw.json', \n",
    "    'drivendata': '/Users/hadleydixon/Desktop/gamification_data_analysis/Data/raw_scraping/drivendata_filtered_results.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 raw competitions from kaggle\n",
      "Loaded 221 raw competitions from aicrowd\n",
      "Loaded 65 raw competitions from drivendata\n"
     ]
    }
   ],
   "source": [
    "raw_data = {}\n",
    "for platform, path in raw_data_paths.items():\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            raw_data[platform] = json.load(f)\n",
    "        print(f\"Loaded {len(raw_data[platform])} raw competitions from {platform}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {path} not found\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Warning: Error parsing JSON from {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame for kaggle with 300 rows\n",
      "Created DataFrame for aicrowd with 221 rows\n",
      "Created DataFrame for drivendata with 65 rows\n"
     ]
    }
   ],
   "source": [
    "raw_dfs = {}\n",
    "for platform, data in raw_data.items():\n",
    "    if data:\n",
    "        raw_dfs[platform] = pd.DataFrame(data)\n",
    "        print(f\"Created DataFrame for {platform} with {len(raw_dfs[platform])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>overview_text</th>\n",
       "      <th>description_text</th>\n",
       "      <th>dataset_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPROD1: Consumer PRODucts contest #1</td>\n",
       "      <td>https://www.kaggle.com/competitions/cprod1</td>\n",
       "      <td>Overview text not found</td>\n",
       "      <td>A significant proportion of web usage relates ...</td>\n",
       "      <td>The CPROD1 competition involves the release of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMC Israel Data Science Challenge</td>\n",
       "      <td>https://www.kaggle.com/competitions/emc-data-s...</td>\n",
       "      <td>Overview text not found</td>\n",
       "      <td>The EMC source code classification challenge r...</td>\n",
       "      <td>Dataset description not found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Practice Fusion Diabetes Classification</td>\n",
       "      <td>https://www.kaggle.com/competitions/pf2012-dia...</td>\n",
       "      <td>Overview text not found</td>\n",
       "      <td>In the first phase of this prediction challeng...</td>\n",
       "      <td>Update: this dataset has been removed at the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detecting Insults in Social Commentary</td>\n",
       "      <td>https://www.kaggle.com/competitions/detecting-...</td>\n",
       "      <td>Overview text not found</td>\n",
       "      <td>The challenge is to detect when a comment fr...</td>\n",
       "      <td>The data consists of a label column followed b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cause-effect pairs</td>\n",
       "      <td>https://www.kaggle.com/competitions/cause-effe...</td>\n",
       "      <td>Overview text not found</td>\n",
       "      <td>Come to our NIPS workshop (dec 9 or 10 in Taho...</td>\n",
       "      <td>This is the July 1, 2013 final data release.  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  \\\n",
       "0     CPROD1: Consumer PRODucts contest #1   \n",
       "1        EMC Israel Data Science Challenge   \n",
       "2  Practice Fusion Diabetes Classification   \n",
       "3   Detecting Insults in Social Commentary   \n",
       "4                       Cause-effect pairs   \n",
       "\n",
       "                                                 url            overview_text  \\\n",
       "0         https://www.kaggle.com/competitions/cprod1  Overview text not found   \n",
       "1  https://www.kaggle.com/competitions/emc-data-s...  Overview text not found   \n",
       "2  https://www.kaggle.com/competitions/pf2012-dia...  Overview text not found   \n",
       "3  https://www.kaggle.com/competitions/detecting-...  Overview text not found   \n",
       "4  https://www.kaggle.com/competitions/cause-effe...  Overview text not found   \n",
       "\n",
       "                                    description_text  \\\n",
       "0  A significant proportion of web usage relates ...   \n",
       "1  The EMC source code classification challenge r...   \n",
       "2  In the first phase of this prediction challeng...   \n",
       "3    The challenge is to detect when a comment fr...   \n",
       "4  Come to our NIPS workshop (dec 9 or 10 in Taho...   \n",
       "\n",
       "                                        dataset_text  \n",
       "0  The CPROD1 competition involves the release of...  \n",
       "1                      Dataset description not found  \n",
       "2  Update: this dataset has been removed at the r...  \n",
       "3  The data consists of a label column followed b...  \n",
       "4  This is the July 1, 2013 final data release.  ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dfs[\"kaggle\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethics_keywords = {\n",
    "    'fairness_bias': {\n",
    "        'fairness', 'bias', 'biased', 'unbiased', 'discrimination',\n",
    "        'equity', 'equitable', 'disparate', 'protected class',\n",
    "        'underrepresented', 'minority', 'marginalized', 'algorithmic bias'\n",
    "    },\n",
    "    \n",
    "    'data_privacy': {\n",
    "        'privacy', 'confidential', 'sensitive',\n",
    "        'PII', 'personal data', 'personal information',\n",
    "        'GDPR', 'consent', 'anonymized', 'pseudonymized',\n",
    "        'de-identified', 'data protection', 'right to be forgotten', 'biometric'\n",
    "    },\n",
    "    \n",
    "    'red_teaming': { \n",
    "        'red team', 'red teaming', 'redteaming', 'adversarial', \n",
    "        'attack', 'exploit', 'exploitation', 'vulnerability',\n",
    "        'penetration testing', 'offensive security'\n",
    "\n",
    "    },\n",
    "    \n",
    "    'transparency_interpretability': {\n",
    "        'transparency', 'transparent', 'explainable', 'explainability', 'XAI',\n",
    "        'interpretable', 'interpretability', 'black box', 'white box', 'glass box',\n",
    "        'model explanation', 'feature importance', 'audit', 'accountability',\n",
    "        'traceability', 'traceable'\n",
    "    },\n",
    "    \n",
    "    'toy_competition': {\n",
    "        'toy', 'toy problem', 'practice', 'practice problem',\n",
    "        'learning', 'learning exercise', 'learning project',\n",
    "        'educational', 'tutorial', 'demo', 'demonstration',\n",
    "        'example', 'sample', 'beginner', 'beginner friendly',\n",
    "        'introductory', 'starter', 'getting started', 'sandbox', 'playground'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regex_patterns(keyword_dicts):\n",
    "    regex_patterns = {}\n",
    "\n",
    "    for category, keywords in keyword_dicts.items():\n",
    "        patterns = []\n",
    "        for keyword in keywords:\n",
    "            pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "            patterns.append(pattern)\n",
    "        \n",
    "        combined_pattern = '|'.join(patterns)\n",
    "        regex_patterns[category] = re.compile(combined_pattern, re.IGNORECASE)\n",
    "\n",
    "    return regex_patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_patterns = create_regex_patterns(ethics_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_keywords_in_text(text, category):\n",
    "    \"\"\"\n",
    "    Check if text contains keywords for a specific category\n",
    "    \"\"\"\n",
    "    if category not in regex_patterns:\n",
    "        return False, []\n",
    "    \n",
    "    pattern = regex_patterns[category]\n",
    "    matches = pattern.findall(text)\n",
    "    \n",
    "    unique_matches = list(set([match.lower() for match in matches]))\n",
    "    \n",
    "    return len(unique_matches) > 0, unique_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fairness_bias(text: str):\n",
    "    return check_keywords_in_text(text, 'fairness_bias')\n",
    "\n",
    "def check_data_privacy(text: str):\n",
    "    return check_keywords_in_text(text, 'data_privacy')\n",
    "\n",
    "def check_red_teaming(text: str):\n",
    "    return check_keywords_in_text(text, 'red_teaming')\n",
    "\n",
    "def check_transparency(text: str):\n",
    "    return check_keywords_in_text(text, 'transparency_interpretability')\n",
    "\n",
    "def check_toy_competition(text: str):\n",
    "    return check_keywords_in_text(text, 'toy_competition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_ethics_categories(text: str):\n",
    "    results = {}\n",
    "    \n",
    "    categories = ['fairness_bias', 'data_privacy', 'red_teaming', 'transparency_interpretability', 'toy_competition']\n",
    "    \n",
    "    for category in categories:\n",
    "        found, matches = check_keywords_in_text(text, category)\n",
    "        results[category] = {\n",
    "            'found': found,\n",
    "            'matches': matches,\n",
    "            'match_count': len(matches)\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_competition_ethics(competition_data):\n",
    "    \"\"\"\n",
    "    Analyze a competition for all ethical considerations\n",
    "    \"\"\"\n",
    "    text_fields = [\n",
    "        competition_data.get('name', ''),\n",
    "        competition_data.get('description_text', ''),\n",
    "        competition_data.get('dataset_text', ''),\n",
    "        competition_data.get('overview_text', '')\n",
    "    ]\n",
    "    \n",
    "    combined_text = ' '.join([field for field in text_fields if field])\n",
    "    \n",
    "    return analyze_all_ethics_categories(combined_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_competition_ethics_json(competition_data):\n",
    "    ethics_analysis = analyze_competition_ethics(competition_data)\n",
    "    \n",
    "    result = {\n",
    "        \"name\": competition_data.get('name', ''),\n",
    "        \"url\": competition_data.get('url', '')\n",
    "    }\n",
    "    \n",
    "    fairness = ethics_analysis.get('fairness_bias', {})\n",
    "    result['fairness_bias_mentioned'] = 'yes' if fairness.get('found') else 'no'\n",
    "    result['how_fairness'] = ', '.join(fairness.get('matches', [])) if fairness.get('found') else 'n/a'\n",
    "    \n",
    "    privacy = ethics_analysis.get('data_privacy', {})\n",
    "    result['data_privacy'] = 'yes' if privacy.get('found') else 'no'\n",
    "    result['how_data_privacy'] = ', '.join(privacy.get('matches', [])) if privacy.get('found') else 'n/a'\n",
    "    \n",
    "    toy = ethics_analysis.get('toy_competition', {})\n",
    "    result['toy'] = 'yes' if toy.get('found') else 'no'\n",
    "    result['how_toy'] = ', '.join(toy.get('matches', [])) if toy.get('found') else 'n/a'\n",
    "\n",
    "    \n",
    "    red = ethics_analysis.get('red_teaming', {})\n",
    "    result['red_team'] = 'yes' if red.get('found') else 'no'\n",
    "    result['how_red_team'] = ', '.join(red.get('matches', [])) if red.get('found') else 'n/a'\n",
    "\n",
    "    \n",
    "    trans = ethics_analysis.get('transparency_interpretability', {})\n",
    "    result['transparency_mentioned'] = 'yes' if trans.get('found') else 'no'\n",
    "    result['how_transparency'] = ', '.join(trans.get('matches', [])) if trans.get('found') else 'n/a'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Practice Fusion Diabetes Classification\",\n",
      "  \"url\": \"https://www.kaggle.com/competitions/pf2012-diabetes\",\n",
      "  \"fairness_bias_mentioned\": \"no\",\n",
      "  \"how_fairness\": \"n/a\",\n",
      "  \"data_privacy\": \"yes\",\n",
      "  \"how_data_privacy\": \"de-identified\",\n",
      "  \"toy\": \"yes\",\n",
      "  \"how_toy\": \"starter, practice\",\n",
      "  \"red_team\": \"no\",\n",
      "  \"how_red_team\": \"n/a\",\n",
      "  \"transparency_mentioned\": \"no\",\n",
      "  \"how_transparency\": \"n/a\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "sample_competition = raw_data['kaggle'][2]\n",
    "json_result = analyze_competition_ethics_json(sample_competition)\n",
    "\n",
    "print(json.dumps(json_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing kaggle dataset...\n",
      "  Processed 50 competitions...\n",
      "  Processed 100 competitions...\n",
      "  Processed 150 competitions...\n",
      "  Processed 200 competitions...\n",
      "  Processed 250 competitions...\n",
      "  Processed 300 competitions...\n",
      "Completed kaggle: 300 competitions processed\n",
      "\n",
      "Processing aicrowd dataset...\n",
      "  Processed 50 competitions...\n",
      "  Processed 100 competitions...\n",
      "  Processed 150 competitions...\n",
      "  Processed 200 competitions...\n",
      "Completed aicrowd: 221 competitions processed\n",
      "\n",
      "Processing drivendata dataset...\n",
      "  Processed 50 competitions...\n",
      "Completed drivendata: 65 competitions processed\n",
      "\n",
      "Saved 300 results to /Users/hadleydixon/Desktop/gamification_data_analysis/Data/kaggle_results/all_pattern_match_results.json\n",
      "Saved 221 results to /Users/hadleydixon/Desktop/gamification_data_analysis/Data/aicrowd_results/all_pattern_match_results.json\n",
      "Saved 65 results to /Users/hadleydixon/Desktop/gamification_data_analysis/Data/drivendata_results/all_pattern_match_results.json\n",
      "\n",
      "All pattern matching results saved!\n"
     ]
    }
   ],
   "source": [
    "# Process all three datasets\n",
    "platforms = ['kaggle', 'aicrowd', 'drivendata']\n",
    "results = {}\n",
    "\n",
    "for platform in platforms:\n",
    "    print(f\"Processing {platform} dataset...\")\n",
    "    \n",
    "    # Initialize list for this platform\n",
    "    platform_results = []\n",
    "    \n",
    "    # Process each competition in the platform\n",
    "    for i, competition in enumerate(raw_data[platform]):\n",
    "        try:\n",
    "            result = analyze_competition_ethics_json(competition)\n",
    "            platform_results.append(result)\n",
    "            \n",
    "            # Progress indicator every 50 competitions\n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"  Processed {i + 1} competitions...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing competition {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    results[platform] = platform_results\n",
    "    print(f\"Completed {platform}: {len(platform_results)} competitions processed\\n\")\n",
    "\n",
    "# Save results to JSON files\n",
    "output_paths = {\n",
    "    'kaggle': '/Users/hadleydixon/Desktop/gamification_data_analysis/Data/kaggle_results/all_pattern_match_results.json',\n",
    "    'aicrowd': '/Users/hadleydixon/Desktop/gamification_data_analysis/Data/aicrowd_results/all_pattern_match_results.json',\n",
    "    'drivendata': '/Users/hadleydixon/Desktop/gamification_data_analysis/Data/drivendata_results/all_pattern_match_results.json'\n",
    "}\n",
    "\n",
    "for platform, results_list in results.items():\n",
    "    output_path = output_paths[platform]\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save to JSON file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Saved {len(results_list)} results to {output_path}\")\n",
    "\n",
    "print(\"\\nAll pattern matching results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gameify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
